{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNR+sKqgNTEUXqNYexhnPr3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BNarayanaReddy/CS7015/blob/main/BackPropImplementation_Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "goZwVGZavgsH"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "height = np.random.normal(loc = 168, scale = 10, size=50) # average 168, deviation 10, size 50\n",
        "weight = np.random.normal(loc = 68, scale = 5, size=50)"
      ],
      "metadata": {
        "id": "to6D_flD8GwT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bmi = weight / (height/100)**2"
      ],
      "metadata": {
        "id": "9FbGZNPV8KAv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = (bmi >= 25).astype(int) # obese = 1 else 0"
      ],
      "metadata": {
        "id": "UBqlpc458K4g"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Network - Multi Label Classification\n",
        "Input (shape: 50, 2) \\\n",
        "      || \\\n",
        "Layer1 (Neurons = 5) \\\n",
        "|| \\\n",
        "Layer 2 (Neurons = 5) \\\n",
        "|| \\\n",
        "Output Layer (Neurons = 1)"
      ],
      "metadata": {
        "id": "a_YjT9Ga8Qwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "height = height.reshape(-1, 1)\n",
        "weight = weight.reshape(-1, 1)"
      ],
      "metadata": {
        "id": "21HxHlll9r0q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.concatenate([height/np.max(height), weight/np.max(weight)], axis = 1)"
      ],
      "metadata": {
        "id": "egZTo-Ts89Ua"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = np.copy(labels).reshape(1,-1)"
      ],
      "metadata": {
        "id": "psHsYM0xEqJU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A77Y3Rpl9jmv",
        "outputId": "de86cf7e-bfb4-4002-c22d-eefe1d35bb0f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.9951731 , 0.77894804])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seett3VVJHMV",
        "outputId": "52b8f4e9-c108-4b3c-902b-d19cb01c0b56"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# weights = [  [<Weights of layer 1, unit 1>, <Weights of layer 1, unit 2>...], [<Weights of layer 2, unit 1>, <Weights of layer 2, unit 2>...]        ]"
      ],
      "metadata": {
        "id": "lZhEWKBt-fL1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights(units, layers = 2, input_dim = 2):\n",
        "  weights = {}\n",
        "  biases = {}\n",
        "  # Hidden layers\n",
        "  for layer in range(1, layers+1):\n",
        "    if layer == 1:\n",
        "      weights[layer] = np.random.randn(units, input_dim)\n",
        "      biases[layer] = np.random.randn(1, units)\n",
        "    else:\n",
        "      weights[layer] = np.random.randn(units, units)\n",
        "      biases[layer] = np.random.randn(1, units)\n",
        "\n",
        "  # Output layer\n",
        "  weights[layers+1] = np.random.randn(1, units)\n",
        "  biases[layers+1] = np.random.randn(1, 1)\n",
        "\n",
        "  return weights, biases"
      ],
      "metadata": {
        "id": "4ScvMmDe9uM5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights, biases = initialize_weights(5, 2)"
      ],
      "metadata": {
        "id": "ncV5Lxvp-X6F"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights[1].shape, weights[2].shape, weights[3].shape, biases[1].shape, biases[2].shape, biases[3].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPgY3bD7D7Cd",
        "outputId": "bdc789eb-d4a3-4c69-fe8c-beb3065c4881"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5, 2), (5, 5), (1, 5), (1, 5), (1, 5), (1, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def activation(z, act_fn):\n",
        "  if act_fn == 'relu':\n",
        "    return np.maximum(0,z)\n",
        "  if act_fn == 'sigmoid':\n",
        "    return 1/(1+np.exp(-z))"
      ],
      "metadata": {
        "id": "GjgtKN6CKHEZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_prop(X, weights, biases, hidden_activation='relu', output_activation = 'sigmoid'):\n",
        "  # m, n = X.shape\n",
        "  a_op = {}\n",
        "  h_op = {}\n",
        "  h_op[0] = X\n",
        "  # hidden\n",
        "  for i in range(1, len(weights)):\n",
        "    w = weights[i]\n",
        "    b = biases[i]\n",
        "    a_op[i] = np.matmul(h_op[i-1], w.T) + b\n",
        "    h_op[i] = activation(a_op[i], hidden_activation)\n",
        "  # output\n",
        "  a_op[len(weights)] = np.dot(weights[len(weights)], h_op[len(weights)-1].T) + biases[len(weights)]\n",
        "  h_op[len(weights)] = activation(a_op[len(weights)], output_activation)\n",
        "\n",
        "  return a_op, h_op"
      ],
      "metadata": {
        "id": "TQXJgxK2D_sv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_op, h_op = forward_prop(X, weights, biases)"
      ],
      "metadata": {
        "id": "2bER1WnWL4MF"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h_op[2].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwpcRrDRL9u_",
        "outputId": "50e9bf61-acb3-4d8e-8779-ff9ac08ec46c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_activation_gradient(a, activ_fn):\n",
        "  grad = np.zeros(a.shape)\n",
        "  if activ_fn == 'relu':\n",
        "    grad[a > 0] = 1\n",
        "  if activ_fn == 'sigmoid':\n",
        "    return a*(1-a)\n",
        "  return grad"
      ],
      "metadata": {
        "id": "KOmoYI2IYA2T"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_op[2].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2yBFdMvXICp",
        "outputId": "8a363dba-a03e-41b7-d00d-5227ce6bd14c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def backpropagation(X, Y, weights, biases, y_pred, output_activation='sigmoid', hidden_activation='relu'):\n",
        "  a_op, h_op = y_pred\n",
        "  op_layer = 3\n",
        "  output_gradient = h_op[op_layer] - Y\n",
        "\n",
        "  grad_w = {}\n",
        "  grad_b = {}\n",
        "\n",
        "  for layer in range(op_layer, 0, -1):\n",
        "    # print(\"Layer: \", layer)\n",
        "    grad_w[layer] = np.dot(output_gradient, h_op[layer-1])\n",
        "    grad_b[layer] = np.sum(output_gradient, axis=1) # 1, 10\n",
        "\n",
        "    hidden_grad = np.dot(weights[layer].T, output_gradient)\n",
        "\n",
        "    # print(compute_activation_gradient(a_op[layer], hidden_activation).shape)\n",
        "\n",
        "    prev_op = a_op[layer]\n",
        "    aggregate_grad = hidden_grad * compute_activation_gradient(h_op[layer-1].T, hidden_activation)\n",
        "\n",
        "\n",
        "    output_gradient = aggregate_grad\n",
        "\n",
        "  return grad_w, grad_b\n",
        "\n"
      ],
      "metadata": {
        "id": "GgyxcN7K2UZW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = forward_prop(X, weights, biases)\n",
        "grad_w, grad_b = backpropagation(X, Y, weights, biases, y_pred)"
      ],
      "metadata": {
        "id": "KG26vVPS2Q8f"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grad_w"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmxK7_eJdrgJ",
        "outputId": "aa111956-61ff-4bfc-e500-05f0c24ef249"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{3: array([[ 0.        ,  0.        ,  0.        , 32.82506231,  0.        ]]),\n",
              " 2: array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
              "        [ 0.        , 45.57962883,  0.        ,  0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ]]),\n",
              " 1: array([[ 0.        ,  0.        ],\n",
              "        [33.54825726, 30.52893006],\n",
              "        [ 0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ]])}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grad_b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EK4wIQk1drYU",
        "outputId": "8ed908c9-3182-4571-c4a1-300008673174"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{3: array([23.47061848]),\n",
              " 2: array([ 0.        ,  0.        ,  0.        , 21.21796642,  0.        ]),\n",
              " 1: array([ 0.        , 36.06543979,  0.        ,  0.        ,  0.        ])}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cost(Y_pred, Y):\n",
        "  return np.mean(-Y*np.log10(Y_pred + 1e-8)-(1-Y)*np.log10(1-Y_pred + 1e-8))"
      ],
      "metadata": {
        "id": "hH5NtuiAfHGz"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_cost(h_op[3], Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kppa7FcMfVGJ",
        "outputId": "a61f4207-32bc-468d-db02-1abc2197c353"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.5768520859706695)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(X, Y, weights, biases, epochs = 100, lr = 1e-3, output_activation='sigmoid', hidden_activation='relu'):\n",
        "  for epoch in range(epochs):\n",
        "    y_pred = forward_prop(X, weights, biases, hidden_activation, output_activation)\n",
        "\n",
        "    if epoch%1== 0:\n",
        "      print(\"Loss:\", compute_cost(y_pred[1][3], Y))\n",
        "\n",
        "    grad_w, grad_b = backpropagation(X, Y, weights, biases, y_pred, output_activation, hidden_activation)\n",
        "\n",
        "    for layer in range(1, len(weights)+1):\n",
        "      weights[layer] -= lr*grad_w[layer]\n",
        "      # print(grad_b[layer].shape)\n",
        "      biases[layer] -= lr*grad_b[layer]\n",
        "\n",
        "  return weights, biases\n",
        "\n"
      ],
      "metadata": {
        "id": "3lUnNTmneOjh"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights, biases = fit(X, Y, weights, biases)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVqgHHNaeOgs",
        "outputId": "c8adf1fe-7d6d-4e20-93b3-cc2c74a39649"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.5768520859706695\n",
            "Loss: 0.5163519594532013\n",
            "Loss: 0.471806917037609\n",
            "Loss: 0.4382592567990767\n",
            "Loss: 0.41242398295925964\n",
            "Loss: 0.3921184679207342\n",
            "Loss: 0.3758740084109058\n",
            "Loss: 0.3628304682515296\n",
            "Loss: 0.353518629861383\n",
            "Loss: 0.34885266193438896\n",
            "Loss: 0.3471226179877796\n",
            "Loss: 0.3456323351143461\n",
            "Loss: 0.34433185140494416\n",
            "Loss: 0.3431514000834311\n",
            "Loss: 0.3419983782117192\n",
            "Loss: 0.3408722138059535\n",
            "Loss: 0.3397723421451993\n",
            "Loss: 0.33869820594590183\n",
            "Loss: 0.3376458418892557\n",
            "Loss: 0.3366070742006816\n",
            "Loss: 0.33559322590814117\n",
            "Loss: 0.3345973028186555\n",
            "Loss: 0.33360540658010435\n",
            "Loss: 0.3326815178818745\n",
            "Loss: 0.33177452298562476\n",
            "Loss: 0.3308994412728184\n",
            "Loss: 0.3300273707311132\n",
            "Loss: 0.3291759367261609\n",
            "Loss: 0.3283556144221894\n",
            "Loss: 0.3275513875415247\n",
            "Loss: 0.32677363355616934\n",
            "Loss: 0.32599826716128666\n",
            "Loss: 0.3252457819978074\n",
            "Loss: 0.32452635068550606\n",
            "Loss: 0.32380413174562533\n",
            "Loss: 0.3231020300255558\n",
            "Loss: 0.32243516977160197\n",
            "Loss: 0.3217626454059929\n",
            "Loss: 0.3211096017385035\n",
            "Loss: 0.3204898942166978\n",
            "Loss: 0.3198637928041775\n",
            "Loss: 0.3192585220188562\n",
            "Loss: 0.3186808707012267\n",
            "Loss: 0.31809809916445947\n",
            "Loss: 0.3175393620650793\n",
            "Loss: 0.31699897971995733\n",
            "Loss: 0.3164566196405893\n",
            "Loss: 0.3159432273626639\n",
            "Loss: 0.3154356228355091\n",
            "Loss: 0.3149309256276229\n",
            "Loss: 0.31446174277759403\n",
            "Loss: 0.3139827073108706\n",
            "Loss: 0.31351993364638436\n",
            "Loss: 0.3130803639693596\n",
            "Loss: 0.3126328235074659\n",
            "Loss: 0.3122128406415584\n",
            "Loss: 0.31179504793982654\n",
            "Loss: 0.3113812682198939\n",
            "Loss: 0.31099794346655674\n",
            "Loss: 0.3106010846179171\n",
            "Loss: 0.31022879115103363\n",
            "Loss: 0.309861180042451\n",
            "Loss: 0.3094948994431786\n",
            "Loss: 0.3091572847918588\n",
            "Loss: 0.30880530549404844\n",
            "Loss: 0.30847932434608305\n",
            "Loss: 0.3081520208335293\n",
            "Loss: 0.30783188377557474\n",
            "Loss: 0.3075305823031391\n",
            "Loss: 0.3072182997035042\n",
            "Loss: 0.30693739265079517\n",
            "Loss: 0.30664159564780263\n",
            "Loss: 0.30636638854831816\n",
            "Loss: 0.30609302956970624\n",
            "Loss: 0.3058236129278102\n",
            "Loss: 0.3055712299907755\n",
            "Loss: 0.3053077668518889\n",
            "Loss: 0.3050618536020239\n",
            "Loss: 0.30483323456090394\n",
            "Loss: 0.30458958941119785\n",
            "Loss: 0.3043666923434416\n",
            "Loss: 0.3041403636922381\n",
            "Loss: 0.3039232791101946\n",
            "Loss: 0.30371304435338875\n",
            "Loss: 0.30350186109187016\n",
            "Loss: 0.30330655319391014\n",
            "Loss: 0.30310135856855064\n",
            "Loss: 0.3029198635701544\n",
            "Loss: 0.3027210171181941\n",
            "Loss: 0.3025389316879084\n",
            "Loss: 0.3023733426935004\n",
            "Loss: 0.3021888599213749\n",
            "Loss: 0.30202922683306044\n",
            "Loss: 0.30185580810570345\n",
            "Loss: 0.3017022199335368\n",
            "Loss: 0.30153893332311554\n",
            "Loss: 0.3013914778409586\n",
            "Loss: 0.30123743369166417\n",
            "Loss: 0.30109619749440647\n",
            "Loss: 0.3009505464771563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights, biases"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8P_Akip9hrKS",
        "outputId": "7f3c89df-4bfe-46c9-95a9-33846ac0a263"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({1: array([[-1.87477186,  1.34086777],\n",
              "         [ 0.24821115,  0.68222708],\n",
              "         [ 0.78757615, -0.46786056],\n",
              "         [-0.26958889, -0.34658808],\n",
              "         [-0.72239546, -1.3002343 ]]),\n",
              "  2: array([[ 0.61835818, -1.09789039, -0.02260026,  0.17276919, -0.85807464],\n",
              "         [ 0.3094141 , -2.34233634,  0.26246131, -0.36688779,  0.46450373],\n",
              "         [ 0.0165342 , -0.84138135,  0.88338392,  0.72177741, -1.13714483],\n",
              "         [ 2.84969247,  1.4391159 ,  1.20722057, -0.39787982, -1.01522527],\n",
              "         [-0.13450709, -1.02466944,  0.09985751, -0.68842921, -1.0032862 ]]),\n",
              "  3: array([[-0.05588111, -0.14075806, -0.3356481 ,  0.79467664, -0.67567899]])},\n",
              " {1: array([[-2.68154548,  0.77417915, -0.84192262, -0.33328873,  0.3916558 ]]),\n",
              "  2: array([[ 0.84034847,  1.38223547, -2.60514503, -2.39058654, -0.56303132]]),\n",
              "  3: array([[-0.00416519]])})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "def serialize(weights, biases, filename='/content/mlp.pkl'):\n",
        "    model = {'weights': weights, 'biases': biases}\n",
        "    with open(filename, 'wb') as file:\n",
        "        pickle.dump(model, file)"
      ],
      "metadata": {
        "id": "3sIejU6ViY5y"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "serialize(weights, biases)"
      ],
      "metadata": {
        "id": "mqLevD_BisYU"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQqoxDfzi19m",
        "outputId": "c51cdbfa-80ea-421a-be3c-fcd5e08a5355"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mlp.pkl  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DV0o66Vti9zS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}